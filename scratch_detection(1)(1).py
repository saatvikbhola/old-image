# -*- coding: utf-8 -*-
"""scratch_detection(1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15byLOvmmVA0OHtE9Yhkczte7_VxlyP3X
"""

!unzip New_folder

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as T
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
from torch.utils.data import random_split, DataLoader
from PIL import Image
import os
import numpy as np
import matplotlib.pyplot as plt
import time

class UNet(nn.Module):
    def __init__(self, in_channels=1, out_channels=1):
        super(UNet, self).__init__()
        self.enc1 = self.conv_block(in_channels, 64)
        self.enc2 = self.conv_block(64, 128)
        self.enc3 = self.conv_block(128, 256)
        self.enc4 = self.conv_block(256, 512)

        self.bottleneck = self.conv_block(512, 1024)

        self.upconv4 = self.upconv_block(1024 + 512, 512)
        self.upconv3 = self.upconv_block(512 + 256, 256)
        self.upconv2 = self.upconv_block(256 + 128, 128)
        self.upconv1 = self.upconv_block(128 + 64, 64)
        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)




    def conv_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.ReLU(inplace=True)
        )

    def upconv_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        # Encoder
        enc1 = self.enc1(x)
        enc2 = self.enc2(F.max_pool2d(enc1, 2))
        enc3 = self.enc3(F.max_pool2d(enc2, 2))
        enc4 = self.enc4(F.max_pool2d(enc3, 2))

        # Bottleneck
        bottleneck = self.bottleneck(F.max_pool2d(enc4, 2))

        # Decoder
        # Upsample bottleneck to match enc4 spatial dimensions
        bottleneck_upsampled = F.interpolate(bottleneck, size=enc4.shape[2:], mode='bilinear', align_corners=False)
        dec4 = self.upconv4(torch.cat([bottleneck_upsampled, enc4], dim=1))

        # Upsample dec4 to match enc3 spatial dimensions
        dec4_upsampled = F.interpolate(dec4, size=enc3.shape[2:], mode='bilinear', align_corners=False)
        dec3 = self.upconv3(torch.cat([dec4_upsampled, enc3], dim=1))

        # Upsample dec3 to match enc2 spatial dimensions
        dec3_upsampled = F.interpolate(dec3, size=enc2.shape[2:], mode='bilinear', align_corners=False)
        dec2 = self.upconv2(torch.cat([dec3_upsampled, enc2], dim=1))

        # Upsample dec2 to match enc1 spatial dimensions
        dec2_upsampled = F.interpolate(dec2, size=enc1.shape[2:], mode='bilinear', align_corners=False)
        dec1 = self.upconv1(torch.cat([dec2_upsampled, enc1], dim=1))

        # Final convolution layer
        out = self.final_conv(dec1)
        return out

class ScratchDetectionDataset(Dataset):
    def __init__(self, image_dir, mask_dir, transform=None, target_size=(256, 256)):
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.transform = transform
        self.target_size = target_size
        self.image_names = sorted(os.listdir(image_dir))

    def __len__(self):
        return len(self.image_names)

    def __getitem__(self, idx):
        img_name = self.image_names[idx]
        img_path = os.path.join(self.image_dir, img_name)
        mask_path = os.path.join(self.mask_dir, img_name)

        image = Image.open(img_path).convert('L')  # Convert to grayscale
        mask = Image.open(mask_path).convert('L')

        image = T.ToTensor()(image)
        mask = T.ToTensor()((np.array(mask) > 128).astype(np.float32))

        # Resize using PyTorch transforms
        image = F.interpolate(image.unsqueeze(0), size=self.target_size, mode="bilinear", align_corners=False).squeeze(0)
        mask = F.interpolate(mask.unsqueeze(0), size=self.target_size, mode="nearest").squeeze(0)

        if self.transform:
            image = self.transform(image)

        return image, mask

transform = T.Compose([
    T.Normalize(mean=[0.5], std=[0.5])  # Example normalization
])

dataset = ScratchDetectionDataset('New folder/images', 'New folder/mask', transform=transform)

# Define the split percentages
train_size = int(0.8 * len(dataset))  # 80% for training
val_size = int(0.1 * len(dataset))    # 10% for validation
test_size = len(dataset) - train_size - val_size  # The remaining for testing

train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

# DataLoader with optimizations
batch_size = 15  # Increase batch size for better GPU utilization
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)

print(f"Training dataset size: {len(train_dataset)}")
print(f"Validation dataset size: {len(val_dataset)}")
print(f"Testing dataset size: {len(test_dataset)}")

# Model, Loss, and Optimizer
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = UNet(in_channels=1, out_channels=1).to(device)
criterion = nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

# Mixed precision training setup
scaler = torch.amp.GradScaler('cuda')

def validate(model, val_dataloader, criterion):
    model.eval()
    val_losses = []
    with torch.no_grad():
        for images, masks in val_dataloader:
            images, masks = images.to('cuda' if torch.cuda.is_available() else 'cpu'), masks.to('cuda' if torch.cuda.is_available() else 'cpu')

            outputs = model(images)
            outputs_resized = F.interpolate(outputs, size=masks.shape[2:], mode="bilinear", align_corners=False)
            loss = criterion(outputs_resized.squeeze(1), masks.squeeze(1))
            val_losses.append(loss.item())

    return val_losses

def test_model_with_metrics(model, dataloader, device, metric='iou'):
    """
    Function to test the model and calculate evaluation metrics such as IoU or Dice Coefficient.

    Args:
    - model: The trained model
    - dataloader: DataLoader for the test/validation set
    - device: Device to run the model ('cuda' or 'cpu')
    - metric: The evaluation metric to use ('iou' or 'dice')

    Returns:
    - metric_value: The calculated evaluation metric (IoU or Dice)
    """
    model.eval()  # Set the model to evaluation mode
    metric_value = 0.0
    num_batches = len(dataloader)

    with torch.no_grad():  # No need to track gradients during evaluation
        for images, masks in dataloader:
            images, masks = images.to(device), masks.to(device)

            # Forward pass
            outputs = model(images)

            # Apply sigmoid to get probability maps (assuming binary classification)
            outputs = torch.sigmoid(outputs)

            # Resize the outputs to match the size of the ground truth masks
            outputs_resized = F.interpolate(outputs, size=masks.shape[2:], mode='bilinear', align_corners=False)

            # Convert the outputs and masks to binary values (0 or 1)
            preds = outputs_resized > 0.5  # Threshold at 0.5 for binary classification
            masks = masks > 0.5  # Threshold the masks similarly

            # Calculate the evaluation metric
            if metric == 'iou':
                metric_value += iou_score(preds, masks)
            elif metric == 'dice':
                metric_value += dice_coefficient(preds, masks)
            else:
                raise ValueError("Metric should be 'iou' or 'dice'")

    # Average the metric over all batches
    metric_value /= num_batches
    print(f"{metric.upper()} Score: {metric_value:.4f}")
    return metric_value

# Function to Train with Gradient Accumulation and Track Training Losses
def train_with_accumulation(model, dataloader, criterion, optimizer, scaler, epochs=10, accumulation_steps=4):
    model.train()
    train_losses = []  # To store training losses per epoch
    val_losses =[]
    for epoch in range(epochs):
        epoch_loss = 0
        optimizer.zero_grad()
        for step, (images, masks) in enumerate(dataloader):
            images, masks = images.to('cuda' if torch.cuda.is_available() else 'cpu'), masks.to('cuda' if torch.cuda.is_available() else 'cpu')

            # Mixed precision training
            with torch.cuda.amp.autocast():
                outputs = model(images)
                outputs_resized = F.interpolate(outputs, size=masks.shape[2:], mode="bilinear", align_corners=False)
                loss = criterion(outputs_resized.squeeze(1), masks.squeeze(1)) / accumulation_steps

            scaler.scale(loss).backward()

            if (step + 1) % accumulation_steps == 0:
                scaler.step(optimizer)
                scaler.update()
                optimizer.zero_grad()

            epoch_loss += loss.item()

        avg_epoch_loss = epoch_loss / len(dataloader)
        train_losses.append(avg_epoch_loss)  # Save the average loss for the epoch
        print(f"Epoch [{epoch + 1}/{epochs}], Training Loss: {avg_epoch_loss}")

        val_loss = validate(model, val_loader, criterion)
        avg_val_loss = sum(val_loss) / len(val_loss)  # Calculate the average validation loss
        val_losses.append(avg_val_loss)
        print(f"Epoch [{epoch + 1}/{epochs}], Validation Loss: {avg_val_loss}")


    return train_losses, val_losses

accumulation_steps = 4

train_losses = train_with_accumulation(model, train_loader, criterion, optimizer, scaler, epochs=60, accumulation_steps=4)

train_loss = train_losses[0]
val_loss = train_losses[1]

plt.plot(train_loss, label='Training Loss')
plt.plot(val_loss, label='validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.ylim(0,0.1)
plt.legend()
plt.grid()
plt.show()

import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
import numpy as np

def test_model(model, test_loader, criterion, device, num_samples=5):
    model.eval()  # Set the model to evaluation mode
    test_loss = 0
    total_samples = 0
    images_list = []
    outputs_list = []
    masks_list = []

    with torch.no_grad():  # Disable gradient computation for testing
        for images, masks in test_loader:
            images, masks = images.to(device), masks.to(device)

            # Forward pass
            outputs = model(images)

            # Resize the outputs to match the mask size
            outputs_resized = F.interpolate(outputs, size=masks.shape[2:], mode="bilinear", align_corners=False)

            # Calculate loss
            loss = criterion(outputs_resized.squeeze(1), masks.squeeze(1))

            test_loss += loss.item() * images.size(0)  # Accumulate loss, scaled by batch size
            total_samples += images.size(0)

            # Collect a few samples for plotting
            images_list.append(images.cpu())
            outputs_list.append(outputs_resized.cpu())
            masks_list.append(masks.cpu())

            if len(images_list) >= num_samples:
                break  # Stop after collecting the specified number of samples

    avg_test_loss = test_loss / total_samples  # Calculate average loss
    print(f"Test Loss: {avg_test_loss:.4f}")

    # Plot the images, masks, and predictions
    images_list = torch.cat(images_list, dim=0)
    outputs_list = torch.cat(outputs_list, dim=0)
    masks_list = torch.cat(masks_list, dim=0)

    fig, axs = plt.subplots(num_samples, 3, figsize=(12, 4*num_samples))

    for i in range(num_samples):
        # Plot the image
        axs[i, 0].imshow(images_list[i].squeeze(0), cmap='gray')
        axs[i, 0].set_title("Image")
        axs[i, 0].axis('off')

        # Plot the ground truth mask
        axs[i, 1].imshow(masks_list[i].squeeze(0), cmap='gray')
        axs[i, 1].set_title("Ground Truth Mask")
        axs[i, 1].axis('off')

        # Plot the predicted mask with colorbar
        predicted_mask = torch.sigmoid(outputs_list[i]).squeeze(0).cpu().numpy()  # Apply sigmoid for probability map
        axs[i, 2].imshow(predicted_mask, cmap='gray')
        axs[i, 2].set_title("Predicted Mask")
        axs[i, 2].axis('off')


    plt.tight_layout()
    plt.show()

    return avg_test_loss

avg_test_loss = test_model(model, test_loader, criterion, device, num_samples=10)

def detect_scratches(model, image_path):
    model.eval()

    # Open image and convert to grayscale (this step is optional, as it's handled in the transform)
    image = Image.open(image_path).convert('L')  # Convert to grayscale

    # Convert the image to tensor
    image_tensor = T.ToTensor()(image).unsqueeze(0)  # Convert PIL image to Tensor and add batch dimension

    # Apply normalization (optional, adjust values as needed)
    image_tensor = T.Normalize(mean=[0.5], std=[0.5])(image_tensor)  # Normalize tensor if needed

    # Move tensor to the same device as the model (GPU/CPU)
    image_tensor = image_tensor.to('cuda' if torch.cuda.is_available() else 'cpu')

    with torch.no_grad():
        output = model(image_tensor)
        output = torch.sigmoid(output.squeeze(0))  # Apply sigmoid to get probability map
        output = (output.squeeze(0).cpu().numpy() * 255).astype(np.uint8)  # Scale to 0â€“255

    plt.imshow(output, cmap='gray')
    plt.colorbar()  # Add colorbar to check intensity values
    plt.show()

detect_scratches(model, '/content/_wsb_192x273_torn+photo+of+soldier+after+restoration.jpg')

# Saving the model
def save_model(model, file_path):
    torch.save(model.state_dict(), file_path)
    print(f"Model saved to {file_path}")

# After training is complete, save the model
save_model(model, 'scratch_detection_model.pth')



!nvidia-smi

